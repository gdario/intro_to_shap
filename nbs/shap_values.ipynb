{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0339b1f9-1d0f-43f3-9241-a86527eec925",
   "metadata": {},
   "source": [
    "# Introduction to SHAP values\n",
    "\n",
    "This notebook aims to clarify the steps described in Lundberg and Lee 2017, with examples and applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a29584d-d066-4485-969e-d16e190ba1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.731]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlinear_func(x):\n",
    "    \"\"\"This function defines a simple nonlinear function of 3 variables.\n",
    "    The three variables correspond to the columns of the input matrix x.\"\"\"\n",
    "    return (0.7 + 1.3 * x[:, 0] -2.1 * x[:, 1]**2 + 1.5 * x[:, 2]**3)\n",
    "\n",
    "print(nonlinear_func(np.array([[0.8, -0.1, 0.2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8bc6b-ff1c-4f87-ab98-e1f3fca800fb",
   "metadata": {},
   "source": [
    "We generate an input dataset of 10,000 triplets of values, where the values are generated according to a multivariate normal distribution with high correlation between the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6606cfc5-45da-4980-be42-52108362456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3141592)\n",
    "means = [0, 0, 0]\n",
    "covmat = [[1, 0.8, 0.9],\n",
    "          [0.8, 1, 0.85],\n",
    "          [0.9, 0.85, 1]]\n",
    "x = np.random.multivariate_normal(mean=means, cov=covmat, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da961d44-6288-4fa8-98c1-5f751da1b3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.79996288, 0.89841072],\n",
       "       [0.79996288, 1.        , 0.84726482],\n",
       "       [0.89841072, 0.84726482, 1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8969e-95b6-4bfd-a324-0c04e69e8bcf",
   "metadata": {},
   "source": [
    "## Additive Attribution Models\n",
    "\n",
    "> The best explanation of a simple model is the model itself.\n",
    "\n",
    "In the case of a *linear model* with **uncorrelated** predictors, the interpretation of the model is straightforward, sin\n",
    "$\\mathbb{E}[f | {x_1, x_2, \\ldots, x_p}] = \\beta_0 + \\beta_1 x_1 + \\ldots \\beta_p x_p$\n",
    "\n",
    "If the predictors are correlated, the interpretation is less obvious. In the extreme case of two almost identical predictors, there is a whole subspace of predictor values that produce the same output, and intepretability at the single predictor level becomes impossible.\n",
    "\n",
    "The fact that linear model with uncorrelated coefficient are the blueprint of an interpretable model suggests two things:\n",
    "\n",
    "1. The interpretability of a model $f(x)$ can be quantified via another model $g(z)$.\n",
    "2. $g(z)$ is a linear model. **TODO** can we prove that the coefficients of $g(z)$ are independent?\n",
    "\n",
    "### Local Explanation Methods\n",
    "\n",
    "Let $f: x \\in \\mathcal{X} \\subseteq \\mathbb{R}^N \\to \\mathcal{Y}$ be the original model. It can be regression, classification, or something else.\n",
    "\n",
    "Let $g: z \\in \\{0, 1\\}^M \\to \\mathcal{Y}'$ be the explanation model.\n",
    "\n",
    "Note that:\n",
    "\n",
    "1. We assume that the the inputs to the $g$ functions take binary vectors as inputs.\n",
    "2. These inputs are called **simplified inputs** for reason that will become clear shortly.\n",
    "4. The output space of the explanatory model is not yet well defined, and we indicate it with $\\mathcal{Y}'$.\n",
    "\n",
    "We assume that $g(z)$ is a **local method**. This means the output of $f(x^*)$ is interpreted based solely on the input $x^*$, and not on any other $x \\in \\mathcal{X} \\subseteq \\mathbb{R}^N$.\n",
    "\n",
    "This is of **crucial importance**: it means that every pair $\\{f(x), y\\}$ has *its own explanation model*. The *functional form* of the explanation model is the same for all $\\{f(x), y\\}$ pairs, but the coefficient of the model vary from pair to pair.\n",
    "\n",
    "So, for any given $x \\in \\mathbb{X}$ there is a $z \\in \\{0, 1\\}^M$ and vice-versa. Note that going from $x$ to $z$ we incur in a loss of information. We introduce a map $h_x(z) \\to x$ but this is not an analytical function, rather it is a rule-based lookup table that associates a $z$ to an $x$ and vice versa. The function $h_x(z)$ is *specific to the input* $x$.\n",
    "\n",
    "**TO THINK ABOUT**\n",
    "\n",
    "> Local methods try to ensure $g(z') \\approx f(h_x(z'))$ whenever $z' \\approx x'$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affde459-db1a-46c6-b7f0-918561f6c297",
   "metadata": {},
   "source": [
    "## Additive Feature Attribution Methods\n",
    "\n",
    "Based on the above discussion, it will not be a surprise that we restrict our attention to local explanation models that have a linear functional form. More precisely\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "g(z) = \\phi_0 + \\sum_{i=1}^M \\phi_i z_i\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $z_i \\in \\{0, 1\\}$ and $\\phi \\in \\mathbb{R}$.\n",
    "\n",
    "The equation above assigns an effect $\\phi_i$ to each *simplified* feature $z_i$. **ARE THESE EFFECTS INDEPENDENT?**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b2001b-e768-40a3-907a-fa8bda585f67",
   "metadata": {},
   "source": [
    "### LIME\n",
    "\n",
    "LIME is presented as an example of a local linear explanation model. Simplified inputs are in the form described above, although their mapping to the original input depends on the data modality (text, images, etc). LIME uses the following optimization method to find the coefficients $\\phi_i$:\n",
    "\n",
    "$$\n",
    "g(z) = \\arg \\min_{g \\in \\mathcal{G}} L(f, g, \\pi_{x'}) + \\Omega(g)\n",
    "$$\n",
    "\n",
    "Where $L$ is a squared loss, $\\pi$ is a weighting kernel, and $\\Omega(g)$ is a regularizing term. We said that each $\\{x, f(x)\\}$ pair has its own set of coefficients, however here the squared loss is minimized\n",
    "> over a set of samples in the simplified input space weighted by the kernel $\\pi_{x'}$.\n",
    "\n",
    "My understanding is the following: we fix $x$ and have a value $f(x)$. $z$ is the simplified input associated with $x$, and $h_x(z) = x$. If $z'$ is another simplified input \"close\" to $z$, the weighting kernel will give it a non-negligible weight. Conversely, if $z$ and $z'$ are \"far apart\" the kernel will set the contribution of $z'$ close to 0. Given $N$ inputs, the loss can be written as\n",
    "\n",
    "$$\n",
    "L(f, g, \\pi_{x'}) = \\sum_{i=1}^N \\left[f(h_x(z)) - g(z^{(i)})\\right]^2 \\pi_{x'}(z^{(i)})\n",
    "$$\n",
    "\n",
    "Where $z^{(i)}$ is the i-th simplified input vector.\n",
    "\n",
    "**VERIFY THIS PART**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b346ec1-818d-4ab0-a1e8-c966d2c2d8a6",
   "metadata": {},
   "source": [
    "### Classic Shapley Value Estimation\n",
    "\n",
    "This approach was developed to deal with linear models in presence of multicollinearity. Let therefore be\n",
    "\n",
    "$f(x) = \\beta_0 + \\beta_1 x_1 + \\ldots \\beta_p x_p$\n",
    "\n",
    "Where $p$ is the total number of predictors ($p+1$, including the intercept). Let $F = \\{x_1, \\ldots, x_p\\}$ be the set of all $p$ features and let $S \\subset F$ be the subset of $F$ where we remove the i-th feature, i.e., $S = F \\setminus \\{i\\}$. There are $2^{p-1}$ possible subsets, including the empty set $\\emptyset$. We then compare the model on the subset $S$, and on the subset $S \\cup \\{i\\}$, i.e., the same subset plus the feature we removed. We have:\n",
    "\n",
    "$ \\delta f_{i} = f_{S \\cup \\{i\\}}(x_{S \\cup \\{i\\}}) - f_S(x_S)$\n",
    "\n",
    "In a linear model $\\delta f_{i} = \\beta_i^S$ where we must add the superscript $S$ to clarify that the value of $\\beta_i$ will be different for every set $S$ we consider (we are fitting a different model every time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418e0a84-c1e4-483b-8b0c-4b5d1814911d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
